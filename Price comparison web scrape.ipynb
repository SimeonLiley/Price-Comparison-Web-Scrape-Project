{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c99c274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import csv\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# for email functionality\n",
    "import smtplib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d4c027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the first target Website URL and pull in data\n",
    "\n",
    "URL1 = 'https://www.amazon.co.uk/Nintendo-Switch-Pokemon-Violet-Pok%C3%A9mon-Violet-Switch/dp/B0B2X4BMV2/ref=sr_1_1?crid=7ILLBVLK4WC&keywords=pokemon+violet&qid=1679752151&sprefix=pokemon+vio%2Caps%2C162&sr=8-1'\n",
    "# user agent found from https://httpbin.org/get\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "\n",
    "page1 = requests.get(URL1, headers=headers) # request data from specified URL\n",
    "\n",
    "page1_code = BeautifulSoup(page1.content, \"html.parser\") # pulling in html content from page\n",
    "\n",
    "page1_code = BeautifulSoup(page1_code.prettify()) # prettify formatting of page_code html data\n",
    "\n",
    "title = page1_code.find(id=\"productTitle\").get_text() # find the product title by searching for the element id\n",
    "price1_pounds = page1_code.find(\"span\", {\"class\": \"a-price-whole\"}).get_text() # price is split into pounds and pence - find the price by searching for the class as no id present\n",
    "price1_pence = page1_code.find(\"span\", {\"class\": \"a-price-fraction\"}).get_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e95df80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the second target Website URL and pull in data\n",
    "\n",
    "URL2 = 'https://www.game.co.uk/en/pok-mon-violet-2878152'\n",
    " \n",
    "page2 = requests.get(URL2, headers=headers) # request data from specified URL\n",
    "\n",
    "page2_code = BeautifulSoup(page2.content, \"html.parser\") # pulling in html content from page\n",
    "\n",
    "page2_code = BeautifulSoup(page2_code.prettify()) # prettify formatting of page_code html data\n",
    " \n",
    "price2 = page2_code.find(\"strong\", {\"class\": \"btnPrice\"}).get_text()  # find the product sell price by searching for the element class\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e830baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tidy data removing enpty space to be ready to import to csv file\n",
    "title = title.strip()\n",
    "price1_pounds = price1_pounds.strip()\n",
    "price1_pounds = price1_pounds.replace(\" \", \"\") # price_pounds has more white space to remove because of a nested element\n",
    "price1_pounds = price1_pounds.replace(\"\\n\", \"\")\n",
    "price1_pence = price1_pence.strip()\n",
    "total_price1 = price1_pounds + price1_pence # concatenate price\n",
    "\n",
    "price2 = price2.strip()\n",
    "price2 = price2.replace(\"£\", \"\")\n",
    "\n",
    "date_of_scrape = datetime.date.today() # date scrape occoured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "68efd371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate price difference and which retailer is cheapest\n",
    "price_difference = float(total_price1) - float(price2) # calculate price difference\n",
    "\n",
    "cheapest_retailer = \"\" # variable declaration to store name of cheapest retailer \n",
    "if price_difference < 0: # find out which retailer is cheaper\n",
    "    cheapest_retailer = \"Amazon\"\n",
    "    price_difference = float(price2) - float(total_price1) # if Game is the cheapest retailer redefine prcie_difference so the value is positive\n",
    "elif price_difference > 0:\n",
    "    cheapest_retailer = \"Gane\"\n",
    "else:\n",
    "    cheapest_retailer = \"Same price\" \n",
    "\n",
    "price_difference = round(price_difference, 2) # Round the price difference to two decimal places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76f9b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare variables for csv file data\n",
    "header = [\"Title\", \"Price at Amazon\", \"Price at Game\", \"Price difference\", \"Cheapest Retailer\", \"Date of Scrape\"] # column headings \n",
    "data = [title, total_price1, price2, price_difference, cheapest_retailer, date_of_scrape] # row data\n",
    "\"\"\" \n",
    "# create csv file - this only needs to be run once, to create the initial file, further addition to file is handled later so commented out so as not to accidentally overwrite additional file data\n",
    "with open(\"PriceComparisonDataset.csv\", \"w\", newline=\"\", encoding=\"UTF8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header) # write column headdings in first row\n",
    "    writer.writerow(data) # write data in next row below headings\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eab7c4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Title  Price at Amazon  Price at Game  \\\n",
      "0  Pokémon Violet (Nintendo Switch)            39.64          39.99   \n",
      "\n",
      "   Price difference Cheapest Retailer Date of Scrape  \n",
      "0              0.35            Amazon     2023-03-25  \n"
     ]
    }
   ],
   "source": [
    "data_frame = pd.read_csv(r\"C:\\Users\\Simeon\\Documents\\Data Science\\Price comparison web scrape\\PriceComparisonDataset.csv\")\n",
    "\n",
    "print(data_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a0215892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine code into a function which we can automate\n",
    "\n",
    "def price_comparison():\n",
    "    # Connect to the first target Website URL and pull in data\n",
    "    URL1 = 'https://www.amazon.co.uk/Nintendo-Switch-Pokemon-Violet-Pok%C3%A9mon-Violet-Switch/dp/B0B2X4BMV2/ref=sr_1_1?crid=7ILLBVLK4WC&keywords=pokemon+violet&qid=1679752151&sprefix=pokemon+vio%2Caps%2C162&sr=8-1'\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "\n",
    "    page1 = requests.get(URL1, headers=headers) # request data from specified URL\n",
    "    page1_code = BeautifulSoup(page1.content, \"html.parser\") # pulling in html content from page\n",
    "    page1_code = BeautifulSoup(page1_code.prettify()) # prettify formatting of page_code html data\n",
    "\n",
    "    title = page1_code.find(id=\"productTitle\").get_text() # find the product title by searching for the element id\n",
    "    price1_pounds = page1_code.find(\"span\", {\"class\": \"a-price-whole\"}).get_text() # price is split into pounds and pence - find the price by searching for the class as no id present\n",
    "    price1_pence = page1_code.find(\"span\", {\"class\": \"a-price-fraction\"}).get_text()\n",
    "\n",
    "    # Connect to the second target Website URL and pull in data\n",
    "\n",
    "    URL2 = 'https://www.game.co.uk/en/pok-mon-violet-2878152'\n",
    "\n",
    "    page2 = requests.get(URL2, headers=headers) # request data from specified URL\n",
    "    page2_code = BeautifulSoup(page2.content, \"html.parser\") # pulling in html content from page\n",
    "    page2_code = BeautifulSoup(page2_code.prettify()) # prettify formatting of page_code html data\n",
    "\n",
    "    price2 = page2_code.find(\"strong\", {\"class\": \"btnPrice\"}).get_text()  # find the product sell price by searching for the element class\n",
    "\n",
    "\n",
    "    # tidy data removing enpty space to be ready to import to csv file\n",
    "    title = title.strip()\n",
    "    price1_pounds = price1_pounds.strip()\n",
    "    price1_pounds = price1_pounds.replace(\" \", \"\") # price_pounds has more white space to remove because of a nested element\n",
    "    price1_pounds = price1_pounds.replace(\"\\n\", \"\")\n",
    "    price1_pence = price1_pence.strip()\n",
    "    total_price1 = price1_pounds + price1_pence # concatenate price\n",
    "\n",
    "    price2 = price2.strip()\n",
    "    price2 = price2.replace(\"£\", \"\")\n",
    "\n",
    "    date_of_scrape = datetime.date.today() # date scrape occoured\n",
    "    \n",
    "    # calculate price difference and which retailer is cheapest\n",
    "    price_difference = float(total_price1) - float(price2) # calculate price difference\n",
    "    cheapest_retailer = \"\" # variable declaration to store name of cheapest retailer \n",
    "\n",
    "    if price_difference < 0: # find out which retailer is cheaper\n",
    "        cheapest_retailer = \"Amazon\"\n",
    "        price_difference = float(price2) - float(total_price1) # if Game is the cheapest retailer redefine prcie_difference so the value is positive\n",
    "    elif price_difference > 0:\n",
    "        cheapest_retailer = \"Gane\"\n",
    "    else:\n",
    "        cheapest_retailer = \"Same price\" \n",
    "\n",
    "    price_difference = round(price_difference, 2) # Round the price difference to two decimal places\n",
    "\n",
    "    # declare variables for csv file data\n",
    "    header = [\"Title\", \"Price at Amazon\", \"Price at Game\", \"Price difference\", \"Cheapest Retailer\", \"Date of Scrape\"] # column headings \n",
    "    data = [title, total_price1, price2, price_difference, cheapest_retailer, date_of_scrape] # row data\n",
    "    \n",
    "    # append data to the csv to track price changes over time\n",
    "    with open(\"PriceComparisonDataset.csv\", \"a+\", newline=\"\", encoding=\"UTF8\") as f:  # write data in the next avaliable row - appends to new row \"a+\" argument\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4737b2d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# automate check_price to run once per day\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mprice_comparison\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[1;32mIn[52], line 8\u001b[0m, in \u001b[0;36mprice_comparison\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m URL1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.amazon.co.uk/Nintendo-Switch-Pokemon-Violet-Pok\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mC3\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mA9mon-Violet-Switch/dp/B0B2X4BMV2/ref=sr_1_1?crid=7ILLBVLK4WC&keywords=pokemon+violet&qid=1679752151&sprefix=pokemon+vio\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m2Caps\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m2C162&sr=8-1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip, deflate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDNT\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpgrade-Insecure-Requests\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m----> 8\u001b[0m page1 \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mURL1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# request data from specified URL\u001b[39;00m\n\u001b[0;32m      9\u001b[0m page1_code \u001b[38;5;241m=\u001b[39m BeautifulSoup(page1\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# pulling in html content from page\u001b[39;00m\n\u001b[0;32m     10\u001b[0m page1_code \u001b[38;5;241m=\u001b[39m BeautifulSoup(page1_code\u001b[38;5;241m.\u001b[39mprettify()) \u001b[38;5;66;03m# prettify formatting of page_code html data\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py:745\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 745\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 899\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\response.py:624\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[1;32m--> 624\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content):\n\u001b[0;32m    625\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m line\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\response.py:828\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 828\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    830\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\response.py:758\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    759\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    760\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1272\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1273\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# automate price_comparison to run once per day\n",
    "while(True):\n",
    "    price_comparison()\n",
    "    time.sleep(86400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0767bc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
